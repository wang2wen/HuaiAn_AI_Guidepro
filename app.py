import streamlit as st
import pandas as pd
from zhipuai import ZhipuAI
import random


# ==============================================================================
# --- SECTION 1: CORE CONFIG & FUNCTIONS ---
# ==============================================================================

def inject_custom_css():
    """Injects custom CSS to style the Streamlit application."""
    st.markdown("""
        <style>
            html, body, [class*="st-"] { font-family: 'PingFang SC', 'Microsoft YaHei', 'Helvetica Neue', 'sans-serif'; }
            [data-testid="stSidebarCollapseButton"] svg, [data-testid="stSidebarCollapseButton"] span { display: none; }
            [data-testid="stSidebarCollapseButton"]::before {
                content: 'â‰¡'; font-size: 24px !important; color: #31333F !important;
                margin-left: 8px; margin-top: 5px; display: inline-block;
            }
            .st-emotion-cache-1c7y2kd { background-color: #F0F2F6; border-radius: 20px 20px 20px 5px; padding: 18px 22px; }
            .st-emotion-cache-4oy321 { background-color: #C9E4FF; border-radius: 20px 20px 5px 20px; padding: 18px 22px; }
            .stButton>button {
                border-radius: 30px; border: 1px solid #E0E0E0; background-color: #FFFFFF;
                width: 100%; transition: all 0.2s ease-in-out; min-height: 60px;
                white-space: normal; word-wrap: break-word; line-height: 1.4;
            }
            .stButton>button:hover { border-color: #007BFF; color: #007BFF; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        </style>
    """, unsafe_allow_html=True)


@st.cache_resource
def initialize_client():
    """Initializes and returns the ZhipuAI client."""
    try:
        api_key = st.secrets.get("ZHIPUAI_API_KEY")
        if not api_key:
            st.error("è¯·åœ¨Streamlit Secretsä¸­è®¾ç½® ZHIPUAI_API_KEYã€‚")
            st.stop()
        return ZhipuAI(api_key=api_key)
    except Exception as e:
        st.error(f"åˆå§‹åŒ–å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
        st.stop()


@st.cache_data
def load_knowledge():
    """Loads knowledge base from the Excel file and pre-processes it."""
    try:
        df = pd.read_excel("huai-an_kb.xlsx")
        df.fillna('', inplace=True)
        if 'ç±»åˆ«' in df.columns:
            df['ç±»åˆ«'] = df['ç±»åˆ«'].str.strip()
        return df
    except FileNotFoundError:
        st.sidebar.error("âŒ æœªæ‰¾åˆ°çŸ¥è¯†åº“ 'huai-an_kb.xlsx'ï¼")
        return pd.DataFrame()
    except Exception as e:
        st.sidebar.error(f"âŒ åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {str(e)}")
        return pd.DataFrame()


def search_knowledge_context(question, df):
    """Searches the knowledge base for an exact question match to get context."""
    if df.empty or not question:
        return ""
    result = df.loc[df['é—®é¢˜'].str.lower() == question.lower(), 'æ ¸å¿ƒçŸ¥è¯†ç‚¹']
    if not result.empty:
        return result.iloc[0]
    # Fallback for questions from chat_input that might not be in the KB
    return "åœ¨æœ¬åœ°çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ä¸æ‚¨è¾“å…¥å®Œå…¨åŒ¹é…çš„é—®é¢˜ã€‚è¯·æ ¹æ®æˆ‘çš„å·²æœ‰çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚"


def get_ai_response_stream(question, context, persona, client, personas_config):
    """Gets a streaming AI response from the ZhipuAI client."""
    prompt = personas_config[persona]["prompt"].format(context=context, question=question)
    try:
        response_stream = client.chat.completions.create(
            model="glm-4-flash",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.75, max_tokens=2048, stream=True
        )
        return (chunk.choices[0].delta.content for chunk in response_stream if chunk.choices[0].delta.content)
    except Exception as e:
        st.error(f"AIæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}")

        def error_generator():
            yield "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚"

        return error_generator()


# ==============================================================================
# --- SECTION 2: STATE MANAGEMENT & UI CALLBACKS ---
# ==============================================================================

def set_category(category):
    """Callback function to set the selected category and reset chat."""
    st.session_state.selected_category = category
    st.session_state.messages = []
    st.session_state.asked_questions = set()


def ask_question(question):
    """Callback function to set the question that needs to be processed."""
    st.session_state.question_to_ask = question


# ==============================================================================
# --- SECTION 3: APP LAYOUT & MAIN SCRIPT ---
# ==============================================================================

st.set_page_config(page_title="æ·®å®‰AIå¯¼æ¸¸å¤©å›¢", page_icon="ğŸ®", layout="centered")
inject_custom_css()

PERSONAS = {
    "è¿å°å®‰": {"icon": "ğŸ“œ", "desc": "é£è¶£å¹½é»˜çš„å†å²ç³»å­¦é•¿",
               "prompt": "ä½œä¸ºâ€œè¿å°å®‰â€ï¼Œä¸€ä½é£è¶£å¹½é»˜çš„å†å²ç³»å­¦é•¿ï¼Œè¯·åŸºäºä»¥ä¸‹çŸ¥è¯†ï¼šã€{context}ã€‘ï¼Œç”ŸåŠ¨æœ‰è¶£åœ°å›ç­”é—®é¢˜ï¼šã€{question}ã€‘"},
    "æ·®åšå£«": {"icon": "ğŸ¤–", "desc": "é«˜æ•ˆç²¾å‡†çš„çŸ¥è¯†å®˜",
               "prompt": "ä½œä¸ºâ€œæ·®åšå£«â€ï¼Œä¸€ä½é«˜æ•ˆç²¾å‡†çš„çŸ¥è¯†å®˜ï¼Œè¯·åŸºäºä»¥ä¸‹çŸ¥è¯†ï¼šã€{context}ã€‘ï¼Œç»“æ„åŒ–ã€æ¸…æ™°åœ°å›ç­”é—®é¢˜ï¼šã€{question}ã€‘"},
    "é˜¿æ·®": {"icon": "ğŸ»", "desc": "çƒ­æƒ…æ¥åœ°æ°”çš„æœ¬åœ°å’–",
             "prompt": "ä½œä¸ºâ€œé˜¿æ·®â€ï¼Œä¸€ä½æ¥åœ°æ°”çš„æ·®å®‰æœ¬åœ°æœ‹å‹ï¼Œè¯·åŸºäºä»¥ä¸‹çŸ¥è¯†ï¼šã€{context}ã€‘ï¼Œç”¨å……æ»¡ç”Ÿæ´»æ°”æ¯çš„å£å»å›ç­”é—®é¢˜ï¼šã€{question}ã€‘"}
}

client = initialize_client()
knowledge_df = load_knowledge()

# --- Initialize Session State ---
if "messages" not in st.session_state: st.session_state.messages = []
if "asked_questions" not in st.session_state: st.session_state.asked_questions = set()
if "selected_category" not in st.session_state: st.session_state.selected_category = None
if "question_to_ask" not in st.session_state: st.session_state.question_to_ask = None

# --- Sidebar UI ---
with st.sidebar:
    st.image("huaianliyunhe_47.png", caption="æ·®å®‰é‡Œè¿æ²³")
    st.header("ğŸ“¢ é€‰æ‹©ä½ çš„AIå¯¼æ¸¸")
    st.radio(
        "é€‰æ‹©å¯¼æ¸¸é£æ ¼:", list(PERSONAS.keys()),
        format_func=lambda x: f"{PERSONAS[x]['icon']} {x} - {PERSONAS[x]['desc']}",
        key="persona_selector"
    )
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è®°å½•", help="æ¸…ç©ºèŠå¤©è®°å½•å¹¶è¿”å›ä¸»é¢˜é€‰æ‹©ç•Œé¢"):
        st.session_state.clear()
        st.rerun()
    if not knowledge_df.empty:
        st.sidebar.success(f"âœ… å·²åŠ è½½ {len(knowledge_df)} æ¡çŸ¥è¯†")

# --- Main Page UI ---
st.title("ğŸ® æ·®å®‰AIå¯¼æ¸¸å¤©å›¢")
st.caption("æˆ‘æ˜¯æ‚¨çš„ä¸“å±æ·®å®‰å¯¼æ¸¸ï¼Œé€‰æ‹©ä¸€ä¸ªä¸»é¢˜ï¼Œå¼€å¯ä¸€åœºâ€œå¡«é¸­å¼â€æ·®å®‰æ–‡åŒ–ä¹‹æ—…å§ï¼")
st.write("---")

# --- Display Chat History from session_state ---
for msg in st.session_state.messages:
    icon = PERSONAS[msg["persona"]]["icon"] if msg["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(msg["role"], avatar=icon):
        st.markdown(msg["content"])

# --- "LIVE" Q&A Handling ---
# Check if a new question has been submitted via a button click or chat input
if st.session_state.question_to_ask:
    question = st.session_state.question_to_ask
    st.session_state.question_to_ask = None  # Reset the state to prevent re-triggering

    # 1. Add user message to history and display it instantly
    st.session_state.asked_questions.add(question)
    st.session_state.messages.append(
        {"role": "user", "content": question, "persona": st.session_state.persona_selector})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(question)

    # 2. Get context and stream the AI response LIVE
    context = search_knowledge_context(question, knowledge_df)
    response_stream = get_ai_response_stream(
        question, context, st.session_state.persona_selector, client, PERSONAS
    )

    with st.chat_message("assistant", avatar=PERSONAS[st.session_state.persona_selector]["icon"]):
        # Use write_stream to render the response live and get the full text
        full_response = st.write_stream(response_stream)

    # 3. Add the complete assistant response to history
    st.session_state.messages.append(
        {"role": "assistant", "content": full_response, "persona": st.session_state.persona_selector})

    # 4. Force a final rerun to clear the "live" part and show the new recommendations
    st.rerun()

# --- Recommendation & Interaction UI ---
if st.session_state.selected_category is None:
    st.subheader("ğŸ’¡ è¯·é€‰æ‹©æ‚¨æ„Ÿå…´è¶£çš„ä¸»é¢˜")
    if not knowledge_df.empty:
        all_categories = sorted(knowledge_df['ç±»åˆ«'].dropna().unique().tolist())
        num_cols = 4
        cat_cols = st.columns(num_cols)
        for i, category in enumerate(all_categories):
            col_index = i % num_cols
            cat_cols[col_index].button(category, key=f"cat_{category}", on_click=set_category, args=(category,))
    else:
        st.warning("çŸ¥è¯†åº“ä¸ºç©ºï¼Œæ— æ³•æ˜¾ç¤ºä¸»é¢˜ã€‚")

else:
    st.subheader(f"çƒ­é—¨é—®é¢˜ Â· {st.session_state.selected_category}")
    category_df = knowledge_df[knowledge_df['ç±»åˆ«'] == st.session_state.selected_category]
    available_qs = [q for q in category_df['é—®é¢˜'].dropna().tolist() if q not in st.session_state.asked_questions]

    if available_qs:
        questions_to_show = random.sample(available_qs, min(3, len(available_qs)))
        q_cols = st.columns(len(questions_to_show))
        for i, q in enumerate(questions_to_show):
            # Use on_click to trigger the question asking logic
            q_cols[i].button(q, key=f"q_{q}", on_click=ask_question, args=(q,))
    else:
        st.success("âœ¨ è¯¥ä¸»é¢˜ä¸‹çš„é—®é¢˜å·²å…¨éƒ¨æ¢ç´¢å®Œæ¯•ï¼")

    if st.button("Â« è¿”å›æ‰€æœ‰ä¸»é¢˜"):
        st.session_state.selected_category = None
        st.rerun()

# --- Chat Input for direct questions ---
if question_from_input := st.chat_input("æ‚¨ä¹Ÿå¯ä»¥ç›´æ¥å‘æˆ‘æé—®..."):
    ask_question(question_from_input)
    st.rerun()